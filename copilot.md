### 特征向量中心性（Eigenvector Centrality）

特征向量中心性是一种衡量网络中节点重要性的方法。它不仅考虑节点本身的连接数量，还考虑这些连接节点的重要性。换句话说，一个节点的重要性不仅取决于它有多少连接，还取决于它连接的节点有多重要。

#### 特征向量中心性的定义

特征向量中心性基于以下思想：一个节点的中心性可以通过它的邻居节点的中心性来定义。具体来说，节点 \(i\) 的特征向量中心性 \(x_i\) 可以表示为：

\[ x_i = \frac{1}{\lambda} \sum_{j \in N(i)} A_{ij} x_j \]

其中：
- \(A_{ij}\) 是邻接矩阵中的元素，如果节点 \(i\) 和节点 \(j\) 之间有边，则 \(A_{ij} = 1\)，否则 \(A_{ij} = 0\)。
- \(N(i)\) 是节点 \(i\) 的邻居节点集合。
- \(\lambda\) 是一个常数（特征值）。

这个方程可以写成矩阵形式：

\[ \mathbf{Ax} = \lambda \mathbf{x} \]

其中：
- \(\mathbf{A}\) 是邻接矩阵。
- \(\mathbf{x}\) 是特征向量中心性向量。
- \(\lambda\) 是对应的特征值。

特征向量中心性是特征值为最大的特征向量的元素。

#### 计算特征向量中心性

在实践中，特征向量中心性可以通过迭代方法来计算，直到收敛为止。NetworkX库提供了计算特征向量中心性的函数 `eigenvector_centrality`。


### 特征向量中心性（Eigenvector Centrality）

特征向量中心性是一种衡量网络中节点重要性的方法。它不仅考虑节点本身的连接数量，还考虑这些连接节点的重要性。换句话说，一个节点的重要性不仅取决于它有多少连接，还取决于它连接的节点有多重要。

#### 特征向量中心性的定义

特征向量中心性基于以下思想：一个节点的中心性可以通过它的邻居节点的中心性来定义。具体来说，节点 \(i\) 的特征向量中心性 \(x_i\) 可以表示为：

\[ x_i = \frac{1}{\lambda} \sum_{j \in N(i)} A_{ij} x_j \]

其中：
- \(A_{ij}\) 是邻接矩阵中的元素，如果节点 \(i\) 和节点 \(j\) 之间有边，则 \(A_{ij} = 1\)，否则 \(A_{ij} = 0\)。
- \(N(i)\) 是节点 \(i\) 的邻居节点集合。
- \(\lambda\) 是一个常数（特征值）。

这个方程可以写成矩阵形式：

\[ \mathbf{Ax} = \lambda \mathbf{x} \]

其中：
- \(\mathbf{A}\) 是邻接矩阵。
- \(\mathbf{x}\) 是特征向量中心性向量。
- \(\lambda\) 是对应的特征值。

特征向量中心性是特征值为最大的特征向量的元素。

#### 选择最大特征值对应的特征向量

在特征向量中心性中，我们选择最大特征值（即主特征值）对应的特征向量。这个特征向量的元素值可以用来表示每个节点的特征向量中心性。选择最大特征值对应的特征向量的原因是：

1. **最大特征值的特征向量具有全局重要性**：最大特征值对应的特征向量在网络中具有全局重要性，能够反映节点在整个网络中的相对重要性。
2. **Perron-Frobenius定理**：对于一个非负矩阵（如邻接矩阵），最大特征值是唯一的实数正特征值，其对应的特征向量也是唯一的非负特征向量（在适当的归一化条件下）。

#### 数学表述

假设邻接矩阵为 \(\mathbf{A}\)，其特征值和特征向量满足：

\[ \mathbf{A} \mathbf{x} = \lambda \mathbf{x} \]

其中，\(\lambda\) 是特征值，\(\mathbf{x}\) 是对应的特征向量。我们选择最大特征值 \(\lambda_{\text{max}}\) 对应的特征向量 \(\mathbf{x}_{\text{max}}\) 作为节点的特征向量中心性。

#### 归一化

为了方便比较和解释，特征向量中心性通常会进行归一化处理，使得特征向量的元素之和为1或使得特征向量的最大值为1。

#### 示例

假设我们有一个邻接矩阵 \(\mathbf{A}\)，其特征值和特征向量如下：

\[ \mathbf{A} = \begin{bmatrix}
0 & 1 & 1 \\
1 & 0 & 1 \\
1 & 1 & 0
\end{bmatrix} \]

计算得到的特征值为 \(\lambda_1 = 2\), \(\lambda_2 = -1\), \(\lambda_3 = -1\)，对应的特征向量分别为：

\[ \mathbf{x}_1 = \begin{bmatrix}
1 \\
1 \\
1
\end{bmatrix}, \quad \mathbf{x}_2 = \begin{bmatrix}
1 \\
-1 \\
0
\end{bmatrix}, \quad \mathbf{x}_3 = \begin{bmatrix}
1 \\
0 \\
-1
\end{bmatrix} \]

我们选择最大特征值 \(\lambda_1 = 2\) 对应的特征向量 \(\mathbf{x}_1 = [1, 1, 1]^T\) 作为节点的特征向量中心性。

#### 结论

通过选择最大特征值对应的特征向量，我们能够有效地衡量节点在网络中的重要性，并且这种方法具有数学上的合理性和稳定性。


### 不可约矩阵的定义

一个方阵 \(\mathbf{A}\) 被称为不可约的，如果对于矩阵 \(\mathbf{A}\) 的任意一个非空真子集 \(S\)（即 \(S\) 是 \(\{1, 2, \ldots, n\}\) 的一个非空真子集），存在 \(i \in S\) 和 \(j \notin S\)，使得 \(\mathbf{A}_{ij} \neq 0\)。

换句话说，矩阵 \(\mathbf{A}\) 是不可约的，如果它不能通过行和列的置换变换为一个块上三角矩阵。不可约矩阵在图论中对应于强连通图。

### 数学表述

设 \(\mathbf{A}\) 是一个 \(n \times n\) 的方阵。如果对于任意的非空真子集 \(S \subset \{1, 2, \ldots, n\}\)，存在 \(i \in S\) 和 \(j \notin S\)，使得 \(\mathbf{A}_{ij} \neq 0\)，则称 \(\mathbf{A}\) 是不可约的。

### 例子

考虑以下矩阵：

\[ \mathbf{A} = \begin{bmatrix}
0 & 1 & 0 \\
0 & 0 & 1 \\
1 & 0 & 0
\end{bmatrix} \]

这个矩阵是不可约的，因为对于任意的非空真子集 \(S\)，总存在 \(i \in S\) 和 \(j \notin S\)，使得 \(\mathbf{A}_{ij} \neq 0\)。

### Perron-Frobenius定理

Perron-Frobenius定理是关于非负矩阵的重要结果。对于不可约的非负矩阵 \(\mathbf{A}\)，Perron-Frobenius定理保证了存在唯一的最大特征值 \(\lambda_{\text{max}}\)，并且对应的特征向量是非负的。